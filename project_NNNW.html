<!DOCTYPE html>

<html>
<head>
  <meta charset="UTF-8">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/p5.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/addons/p5.dom.min.js"></script>
  <script src="https://unpkg.com/ml5@latest/dist/ml5.min.js" type="text/javascript"></script>
</head>
<title>MF</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="/W3_CSS mod.css">
<body style="background-image: linear-gradient(rgba(123.68,116.779,103.939,1), rgba(10,10,10,1))">
<style>
body, h1, h3, h4, h5, h6 {
  font-family: "Times New Roman", serif;
  font-size: 16px;
  text-align: justify;
}
</style>
<body>
    
<!-- Navbar (sit on top) -->
<div class="w3-top">
  <div class="w3-bar A-transparent-back w2-wide">
    <a href="https://mediaforensis.agency/#home" class="w3-bar-item w3-button drop-shadow-3p" style="letter-spacing:1px; font-size:90px; color:rgba(255, 255, 255, 0); font-family:robo; line-height: 90px">MF</a>
    <!-- Float links to the right. Hide them on small screens -->
    <div class="w3-right w3-hide-small">
      <a href="https://mediaforensis.agency/#projects" class="w3-bar-item w3-button drop-shadow-3p" style="letter-spacing:1px; font-size:25px; color:rgba(255, 255, 255, 0); font-family: Museo; line-height: 20px"><b>cases</b></a>
      <br>
      <a href="https://mediaforensis.agency/#about" class="w3-bar-item w3-button drop-shadow-3p" style="letter-spacing:1px; font-size:25px; color:rgba(255, 255, 255, 0); font-family: Museo; line-height: 20px"><b>about</b></a>
      <br>
      <a href="https://mediaforensis.agency/#texts" class="w3-bar-item w3-button drop-shadow-3p" style="letter-spacing:1px; font-size:25px; color:rgba(255, 255, 255, 0); font-family: Museo; line-height: 20px"><b>texts</b></a>
      <br>
      <a href="https://mediaforensis.agency/#edu" class="w3-bar-item w3-button drop-shadow-3p" style="letter-spacing:1px; font-size:25px; color:rgba(255, 255, 255, 0); font-family: Museo; line-height: 20px"><b>edu</b></a>
      <br>
      <a href="https://mediaforensis.agency/#contact" class="w3-bar-item w3-button drop-shadow-3p" style="letter-spacing:1px; font-size:25px; color:rgba(255, 255, 255, 0); font-family: Museo; line-height: 20px"><b>contact</b></a>
    </div>
  </div>
</div>

<!-- Full size image -->
  <img src="/NNNW/NNNW_img - header_sh.jpg" style="width:100%">

<!-- Page content -->
<div class="w3-content w3-padding" style="max-width:1564px">

    <div class="w3-container">
        <h2 class="drop-shadow robo-font" style="color:#ffffff; font-size:90px; line-height: 90px">NEW NEW NEW WORLD</h2>
      <p style="color:#ffffff; font-size:17px; font-family: SpaceGL">An IN PROCESS research on computational worlding through machine (en)vision from a post-postcolonial perspective.</p>
      <hr>
    </div>
</div>
	
<!------------------------------------------------------------------------- The NewNewNewWorld and the New World ----------------------------------------------------->
<div class="w3-container w3-padding-32" id="retratos">
  <h3 class="w3-border-bottom w3-border-light-grey w3-padding-16 Museo-font"  style="color:#ffffff; font-size: 25px">The NewNewNewWorld and the New World</h3>
</div>

<div class="w3-panel" style="margin: auto; width:1000px">
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Inside an abstract place, within a virtual reality, across a latent space, you can find the territory of the NewNewNewWorld (NNNW). Centuries ahead of the New World as found by the XV century colonial Europe –subsequent to the Contemporary world as well–, the worlding of it –the worldbuilding of it– seems to require a post-post-colonial politics as it is not only to be discovered but, just as the New World to some extent, to be also generated.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">At the moment, the NNNW only exists within the memory of the AI model that knows better than every other AI what the human world looks like: the BigGAN. To acquire such knowledge, BigGAN was trained on ImageNet –for years, the largest dataset for AI training, assembled to “map the entire world of objects”, according to its creators–, which made it capable of generating accurate images of the more-than-20 thousand ImageNet object classes, comprehending around 14 million tagged images. Born from a “large scale GAN training for high fidelity natural image synthesis” (Andrew Brock + Jeff Donahue + Karen Simonyan, 2019), it is capable of “artificial” image synthesis –more precisely, synthesis of artificial objects. Within its Latent Space, a series of new new new objects –or Xenobjects, as I call them–, all of them differentiable from ImageNet’s object classes in which it was trained, potentially exists. Even after having landed on the NNNW and having developed a basic cosmography of it already, I wonder if “we are still far from understanding the hidden world of the [BigGAN’s] latent space” (Zaid Alyafeaid, 2019).
	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Importantly, the virtual existence of all of these xenobjects is also non-correlated to our human capability of imagining possible worlds. To be clear: it is the BigGAN itself who imagines these xenobjects. It was not trained on them and they didn’t exist in the brains of humans nor in any other media, and they were not plannead neither anticipated –though they are now latent in my computer and they are latent in yours if you download it. This is actually the whole point with Machine Learning, with this specific type of AI and with everything called Software 2.0 (Andrej Karpathy, 2017); instead of following the “classical stack” in which the human programmer wites every line of code that, given some input, the computer will read and execute in order to complete a task and yield an output –in this case, the synthesis of a 512 x 512 pixels image–, the human developer moves to the sides, preparing a dataset that defines a desired goal for the behavior of the program –as well as a “skeleton” of the code–, and lets the computer learn how to come up with the appropriate program on the basis of massive iterations of trial and error. Millions of photographs of the Current World come in, a simulant worlding process runs, and images surprisingly resemblant of the Current World come out. Nevertheless, an Old World can go in, a non-expected worldbuilding can occur, and a New World can go out –which is exactly what happened in the XV and XVI centuries after europeans arrived to the Americas.
	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">In fact, before geography revealed to europeans that they didn’t arrived to the unknown Indies, they have already projected onto the Americas what they speculated about the known Indies. But when encountering actual land, people, animals, and other objects, they mediated their own knowledge importing fantasy scripts in a generative fashion. In the early years of explorations…
	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">“...no one had specific knowledge about the New World. Early sixteenth-century commercial contracts between the [Spanish] crown and entrepreneurs refer to common commodities such as precious metals, precious stones, plants, animals, fish, birds, medicines, and ‘any thing of any name and quality’ of value. Some of these contracts referred to ‘monsters’ and ‘serpents’ (Vas Mingo 1986 [Las Capitulaciones de Indias en el siglo XVI]).” (Antonio Barrera-Osorio, 2007)
	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">The outputs of Spaniards and other “discoverers” also included other less indiferent creatures, like the Epaiwanoma, those headless people with their eyes and mouth in their chest. Jodocus Hondius depicted them in his chart 1598 chart of The Guianas (now French Guiana, Suriname and Guyana) and his map of North America –him among other cartographers who represented the Epaiwanoma in other parts of the Americas and beyond. The very long exploration and colonization process by the Spaniards was documented in very unregulated ways at the beginning and then increasingly organized by changing insitutions designated by the crown, ultimately being preserved mostly by the Archivo General de Indias, currently located in Seville, Spain. As Epaiwanoma were projected into maps, Quetzalcóatl and other local inventions were disappeared from the territory. If “a world in fact is the projection of meaningful patterns onto the surrounding space of lived experience” (Berardi, 2015), then the Current World for the pre-columbian Mesoamerican cultures ended as a World emerged anew for both the colonized and the colonizers. In the following centuries, for both, the monsters transformed but hardly disappeared.
	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">What the BigGAN learned from ImageNet was, precisely, patterns in the space surrounding humans with digital cameras. It imported categories, such as “puppy”, “cross-country riding” and “globigerina”, but mostly it apprehended pixel arrangements at different scales: how deconstructed sets of color squares organize together across JPEG files previously separated in folders. Similarly to the New World, the NNNW is emerging form the gathering of fragmentary patterns of the Current World, taking bits from #snail and #skonk, and pieces from #strawberry and #chihuahua (and many more), giving shape to a #wildBot or an #UnidentifiedNavigatingObject. I’m not sure if I see the catastrophe on the interface –or “the past coming apart” (Land and Plant 1994)– but I do see the “anastrophe” –or “the future coming together”.
	</p>
</div>
<!------------------------------------------------------------------------- NewNewNewWorld_Constructor ----------------------------------------------------->
<div class="w3-container w3-padding-32" id="retratos">
  <h3 class="w3-border-bottom w3-border-light-grey w3-padding-16 Museo-font"  style="color:#ffffff; font-size: 25px">NewNewNewWorld_Constructor</h3>
</div>

<div class="w3-panel" style="margin: auto; width:1000px">
	<p style="color:#ffffff; font-size:17px; font-family: Museo">But… is the NNNW really coming together? Is the BigGAN actually printing a New New New World on my screen? Is the BigGAN constructing it for sure, or is it just me projecting patterns on your surrounding space? Is the BigGAN a NNNW_Constructor?
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">I will try to answer that question in terms of Constructor Theory, a theory in current development by David Deutsch and Chiara Marletto at the University of Oxford. This theory investigates which things (and transformations) can and cannot occur in the universe by means of a constructor (a machine) that performs (and can repeat) a task, proving a transformation and a resulting thing to be possible, which can finally be expressed in a “counterfactual statement”. In the case of this research, the counterfactual statement would assert that a New New New World (of objects) can be generated (i.e. can be imagined, can be printed as a digital image) by the BigGAN. Counterfactuals come relevant to this research on worldbuilding –and worldbuilding research–, as a counterfactual statement “describes how the world would have been if the antecedent [declared in the statement] had obtained” (ESSRM, 2004). “If P had obtained, then Q would have obtained”. If (not) P, then (not) Q. “If the BigGAN was only ably to reproduce the objects in the ImageNet dataset, then only objects in ImageNet would be its output”. According to Marletto, “a counterfactual is a statement about which transformations are possible and which are impossible in a physical system”, and “a transformation is possible when you have a ‘constructor’ that can perform a task and then retain the capacity to perform it again” (in Gefter, 2021), say a NNNW_Constructor that can generate a new xenobject many times. That would mean to generate multiple objects that are different from ImageNet’s –i.e. xenobjects–, but also different from the already generated xenobjects.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">The assesment of the BigGAN as a NNNW_Constructor involves two technical devices. The first one, a NNNW_Archive, is a dataset comprised by hundreds of classified xenobjects. Thse second one, a NNNW_Explorer, is a Machine Learning model trained on the NNNW_Archive. The NNNW_Explorer, an image classifier, will compare the resemblance of new xenobjects to, both, ImageNet classes and NNNW’s classes, and that should provide a measure of how much the BigGAN is generating, not an ImageNet world nor noise, but a NNNW.
     	</p>
</div>
<!------------------------------------------------------------------------- NewNewNewWorld_Archive ----------------------------------------------------->
<div class="w3-container w3-padding-32" id="retratos">
  <h3 class="w3-border-bottom w3-border-light-grey w3-padding-16 Museo-font"  style="color:#ffffff; font-size: 25px">NewNewNewWorld_Archive</h3>
</div>

<div class="w3-panel" style="margin: auto; width:1000px">
	<p style="color:#ffffff; font-size:17px; font-family: Museo">By the 1570’s, personal experience of merchants and explorers, beyond ecclesiastical and academic imaginary, “had become the indispensable tool for the study of natural things in the New World”, “a nature without referents in the classical traditions” according to Antonio Barrera-Osorio (2007), who argues that a strongly enhanced tendency towards empiricism within this process locates the beginning of the Scientific Revolution in the Iberic Peninsula. Nature, be it minerals or pineapples, were primarily conceived as commodities –i.e. “as a collection of isolated and extractible entities”. As merchants and explorers were the first intermediaries for the creation of knowledge about found nature (found culture not excluded), “empirical descriptions of these entities became the prevailing method for understanding them”. Personal observation, interviews, and expeditions, all translated to drawn and written reports, was the basis for collective and remote recognition; they circulated from hand to hand across networks that connected indigenous daily life, English academia, and the Spanish crown. Throughout these networks, representational patterns got enhanced, lessened, and nuanced to various degrees according to the accumulating experience of each involved agent.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Spain, says Barrera-Osorio, “was the first imperial and commercial power to create institutions for gathering, organizing, and disseminating empirical information about the New World”. In 1508, the crown established the position of the chief pilot at the Casa de Contratación, which “would become a veritable chamber of knowledge from this poin on” (Barrera-Osorio, 2007). The chief pilot would help “to correct personal bias by comparing several reports on the same topic, and by evaluating personal observation in the Casa’s social setting of expert evaluators”. Through such institutions, “they sought to train people in the new methods [of knowledge production and management] emerging from these activities”. I would argue that people got trained, not only in the protocols for processing the constituting patterns of the New World, but also in the very patterns they were processing. These New World-processing institutions served to gather and shape New World knowledge through the harvesting of information generated by large networks of empirically-driven agents and its evaluation by output discriminators. Were these information-processing systems the first Machine Learning systems –or as called in Spanish, Automated Learning systems?
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Just as the Archivo General de Indias was the dataset in which the New World Constructors were (unevenly) trained, the NNNW_Archive is the memory in which I’m training human and non-human explorers –i.e. myself and an artificial co-pilot. The NNNW_Archive is the generation of a large diversity of Xenobjects that can be organized in differentiable categories which nevertheless contain differentiable instances (e.g., distinguishable #stemBot examples that can be all identified as #stemBot). Through this novel training set, through this post-contemporary General Archive of Indies, the NNNW will be able to infiltrate into the sentience of other AIs, to propagate its influence on the transformations of the present material world, and to occupy a place in the future.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Across the multidimensional territory of the NNNW, you can find xenobjects like a wildBot –undisclosedly carbon- or silicon-based, most likely who knows– wandering around in all kinds of environments, doing whatever thing of any name and utility. Another kind of xenobject you can stumble upon is arRock, which is not only a rock but something arising from it as if being synthesized directly from mineral stratum. There’s also stemBots, xenobjects of seemingly very small dimentions and a persisting latent state. I wonder if perhaps they evolve into wildBots or maybe stillArchitecture, which is still something that looks like the objects in which humans use to inhabit but which could turn into an UnidentifiedNavigatingObject at any moment. Do they actually evolve? do they merge and separate under changing conditions? Do they form from local matter and dissolve into it? I really wonder.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Those are just some of the xenobjects I’ve come across, but there may be plenty of them which I cannot recognize. I wish I could. I reality, there’s only a few characteristics that allow me to become aware of them, to extract them and save them on my drive, to search for them and print them, either temporarily on my screen or permanently in other substrates that would give them width, height and depth. I’m here to augment their reality, and for that to have the broadest set of possible outcomes, they have to be segmentable and photographically realistic –i.e. I have to be able to distinguish them from the background and I must feel I could 3D-sculpt them. Width, height, depth, and time are less dimensions than the > 21’000 dimensions of the BigGAN’s latent space, but those are the dimensions I can help them to inhabit as those are the dimensions (or the elemental technical abstractions) of the world that I inhabit myself.
     	</p>
</div>
<!------------------------------------------------------------------------- NNNW_Archive - CLASSES -------------------------------------------------------------------->

<!------------------------------------------------------------------------- arRock -->
<div class="w3-panel">
	<div class="w3-panel">
		<p style="color:#fff; font-size:15px; font-family: SpaceGL">class arRock</p>
	</div>
</div>

<div class="w3-content w3-display-container">
  <button class="w3-button w3-black" style="width:100%" onclick="plusDivs(1)">&#10095;</button>
	
  	<img class="mySlides" src="/NNNW/arRock/0ea16a82776f0c8f81ca2f8b.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/1e620e8ba5718ccf1fcca439.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/2b802717df5c7861de3de5d5.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/2d6676ac503651c0fe2a1069.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/3ff806458f9e82890a4bfaa5.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/420cb718efb2f02835153822.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/58f0e03afe6744a99d333647.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/5f6b20a479d0eb95dad839cb.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/7f7d96c093585d869f262862.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/9d7379cb0c67a566f09cc26a.png" style="width:25%">

  <button class="w3-button w3-black" style="width:100%" onclick="plusDivs(-1)">&#10094;</button>
</div>
<!--
<div class="w3-content w3-display-container w3-center">
  <button class="w3-button w3-black" style="width:25%" onclick="plusDivs(-1)">&#10094;</button>
	
  	<img class="mySlides" src="/NNNW/arRock/0ea16a82776f0c8f81ca2f8b.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/1e620e8ba5718ccf1fcca439.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/2b802717df5c7861de3de5d5.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/2d6676ac503651c0fe2a1069.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/3ff806458f9e82890a4bfaa5.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/420cb718efb2f02835153822.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/58f0e03afe6744a99d333647.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/5f6b20a479d0eb95dad839cb.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/7f7d96c093585d869f262862.png" style="width:25%">
	<img class="mySlides" src="/NNNW/arRock/9d7379cb0c67a566f09cc26a.png" style="width:25%">

  <button class="w3-button w3-black" style="width:25%" onclick="plusDivs(1)">&#10095;</button>
	<!--<button class="w3-button w3-black w3-display-right" onclick="plusDivs(1)">&#10095;</button>-->
</div>
<script>
var slideIndex = 1;
showDivs(slideIndex);

function plusDivs(n) {
  showDivs(slideIndex += n);
}

function showDivs(n) {
  var i;
  var x = document.getElementsByClassName("mySlides");
  if (n > x.length) {slideIndex = 1}
  if (n < 1) {slideIndex = x.length}
  for (i = 0; i < x.length; i++) {
    x[i].style.display = "none";  
  }
  x[slideIndex-1].style.display = "block";
}
</script>

<!------------------------------------------------------------------------- disOrgan -->
<div class="w3-panel">
	<div class="w3-panel">
		<p style="color:#fff; font-size:15px; font-family: SpaceGL">class disOrgan</p>
	</div>
</div>
	
<div class="w3-content w3-display-container">
  	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs2(1)">&#10095;</button>
	
  	<img class="mySlides2" src="/NNNW/disOrgan/1bef58fd05af60204f2607ab.png" style="width:25%">
	<img class="mySlides2" src="/NNNW/disOrgan/2e996084f64b48e618f853de.png" style="width:25%">
	<img class="mySlides2" src="/NNNW/disOrgan/32db0d09f444bc33bdbfd032.png" style="width:25%">
	<img class="mySlides2" src="/NNNW/disOrgan/3349d308fb23a806ae07f11a.png" style="width:25%">
	<img class="mySlides2" src="/NNNW/disOrgan/3d08a27a780cf82a81fa6059.png" style="width:25%">
	<img class="mySlides2" src="/NNNW/disOrgan/448d84f0c520f4efa20e4b9c.png" style="width:25%">
	<img class="mySlides2" src="/NNNW/disOrgan/626614001a6a78ef64ead700.png" style="width:25%">
	<img class="mySlides2" src="/NNNW/disOrgan/a18353e19ad5e0ecd77b062c.png" style="width:25%">
	<img class="mySlides2" src="/NNNW/disOrgan/a32bd397d87ec6580bb072ad.png" style="width:25%">
	<img class="mySlides2" src="/NNNW/disOrgan/e9e88bc46e2b5a812d7acfa9.png" style="width:25%">

	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs2(-1)">&#10094;</button>
</div>
<script>
var slideIndex2 = 1;
showDivs2(slideIndex2);

function plusDivs2(n) {
  showDivs2(slideIndex2 += n);
}

function showDivs2(n) {
  var j;
  var y = document.getElementsByClassName("mySlides2");
  if (n > y.length) {slideIndex2 = 1}
  if (n < 1) {slideIndex2 = y.length}
  for (j = 0; j < y.length; j++) {
    y[j].style.display = "none";  
  }
  y[slideIndex2-1].style.display = "block";  
}
</script>

<!------------------------------------------------------------------------- shellish -->
<div class="w3-panel">
	<div class="w3-panel">
		<p style="color:#fff; font-size:15px; font-family: SpaceGL">class shellish</p>
	</div>
</div>
	
<div class="w3-content w3-display-container">
  	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs3(1)">&#10095;</button>
	
  	<img class="mySlides3" src="/NNNW/shellish/05c670574db383632228edd2.png" style="width:25%">
	<img class="mySlides3" src="/NNNW/shellish/09b0911facf640f9ebc5b41f.png" style="width:25%">
	<img class="mySlides3" src="/NNNW/shellish/203d45be0125c795d95340f5.png" style="width:25%">
	<img class="mySlides3" src="/NNNW/shellish/5157064e3be58feffee8cc6e.png" style="width:25%">
	<img class="mySlides3" src="/NNNW/shellish/5be16f86690eb0d9b39d35d3.png" style="width:25%">
	<img class="mySlides3" src="/NNNW/shellish/7557f1ee6a6cfe19765ed10f.png" style="width:25%">
	<img class="mySlides3" src="/NNNW/shellish/77edf455ab5d31d728acce06.png" style="width:25%">
	<img class="mySlides3" src="/NNNW/shellish/7a57eee98097ca5441504a68.png" style="width:25%">
	<img class="mySlides3" src="/NNNW/shellish/7f9d46167b37b0585b8c2392.png" style="width:25%">
	<img class="mySlides3" src="/NNNW/shellish/c7ad33d885ed2e4a5d746bf3.png" style="width:25%">

	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs3(-1)">&#10094;</button>
</div>
<script>
var slideIndex3 = 1;
showDivs3(slideIndex3);

function plusDivs3(n) {
  showDivs3(slideIndex3 += n);
}

function showDivs3(n) {
  var k;
  var a = document.getElementsByClassName("mySlides3");
  if (n > a.length) {slideIndex3 = 1}
  if (n < 1) {slideIndex3 = a.length}
  for (k = 0; k < a.length; k++) {
    a[k].style.display = "none";  
  }
  a[slideIndex3-1].style.display = "block";  
}
</script>
	
<!------------------------------------------------------------------------- stemBot -->
<div class="w3-panel">
	<div class="w3-panel">
		<p style="color:#fff; font-size:15px; font-family: SpaceGL">class stemBot</p>
	</div>
</div>
	
<div class="w3-content w3-display-container">
  	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs4(1)">&#10095;</button>
	
  	<img class="mySlides4" src="/NNNW/stemBot/029c0fa00dc0f90c6de7e359.png" style="width:25%">
	<img class="mySlides4" src="/NNNW/stemBot/0d029d383c440062ad7109ad.png" style="width:25%">
	<img class="mySlides4" src="/NNNW/stemBot/0ed470fa621510c20bd8.png" style="width:25%">
	<img class="mySlides4" src="/NNNW/stemBot/2b3e3267cbe7b91d7437aa8f.png" style="width:25%">
	<img class="mySlides4" src="/NNNW/stemBot/3a26fd172c5378d8dcedd5d3.png" style="width:25%">
	<img class="mySlides4" src="/NNNW/stemBot/3e2bd0e7ffa785aed611e2c7.png" style="width:25%">
	<img class="mySlides4" src="/NNNW/stemBot/4f046a5d0e7d972f56497c99.png" style="width:25%">
	<img class="mySlides4" src="/NNNW/stemBot/5e4c8bd55c0e15b073baca0a.png" style="width:25%">
	<img class="mySlides4" src="/NNNW/stemBot/8c8c6d37e8501473e4a8.png" style="width:25%">
	<img class="mySlides4" src="/NNNW/stemBot/8d9e83518f863e0c9efb.png" style="width:25%">

	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs4(-1)">&#10094;</button>
</div>
<script>
var slideIndex4 = 1;
showDivs4(slideIndex4);

function plusDivs4(n) {
  showDivs4(slideIndex4 += n);
}

function showDivs4(n) {
  var l;
  var b = document.getElementsByClassName("mySlides4");
  if (n > b.length) {slideIndex4 = 1}
  if (n < 1) {slideIndex4 = b.length}
  for (l = 0; l < b.length; l++) {
    b[l].style.display = "none";  
  }
  b[slideIndex4-1].style.display = "block";  
}
</script>
	
<!------------------------------------------------------------------------- stillArchitecture -->
<div class="w3-panel">
	<div class="w3-panel">
		<p style="color:#fff; font-size:15px; font-family: SpaceGL">class stillArchitecture</p>
	</div>
</div>
	
<div class="w3-content w3-display-container">
  	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs5(1)">&#10095;</button>
	
  	<img class="mySlides5" src="/NNNW/stillArchitecture/051688e6999b968ff9333b6e.png" style="width:25%">
	<img class="mySlides5" src="/NNNW/stillArchitecture/106c09a57e3b848734d871da.png" style="width:25%">
	<img class="mySlides5" src="/NNNW/stillArchitecture/1c08fcc602f26d046063fbaf.png" style="width:25%">
	<img class="mySlides5" src="/NNNW/stillArchitecture/4c5e575eb0fdee03f8eeae6b.png" style="width:25%">
	<img class="mySlides5" src="/NNNW/stillArchitecture/4e2b888f78430bb231f8c236.png" style="width:25%">
	<img class="mySlides5" src="/NNNW/stillArchitecture/820d85aeb2c69c1e8ece5838.png" style="width:25%">
	<img class="mySlides5" src="/NNNW/stillArchitecture/98dbba50191f2f53a83aa6a7.png" style="width:25%">
	<img class="mySlides5" src="/NNNW/stillArchitecture/bd708cfe8772b303d05388c3.png" style="width:25%">
	<img class="mySlides5" src="/NNNW/stillArchitecture/e0485c547348793c70a581a7.png" style="width:25%">
	<img class="mySlides5" src="/NNNW/stillArchitecture/e4c13409319a6b4258693a19.png" style="width:25%">

	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs5(-1)">&#10094;</button>
</div>
<script>
var slideIndex5 = 1;
showDivs5(slideIndex5);

function plusDivs5(n) {
  showDivs5(slideIndex5 += n);
}

function showDivs5(n) {
  var m;
  var c = document.getElementsByClassName("mySlides5");
  if (n > c.length) {slideIndex5 = 1}
  if (n < 1) {slideIndex5 = c.length}
  for (m = 0; m < c.length; m++) {
    c[m].style.display = "none";  
  }
  c[slideIndex5-1].style.display = "block";  
}
</script>
	
<!------------------------------------------------------------------------- UnidentifiedNavigatingObject -->
<div class="w3-panel">
	<div class="w3-panel">
		<p style="color:#fff; font-size:15px; font-family: SpaceGL">class UnidentifiedNavigatingObject</p>
	</div>
</div>
	
<div class="w3-content w3-display-container">
  	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs6(1)">&#10095;</button>
	
  	<img class="mySlides6" src="/NNNW/UnidentifiedNavigatingObject/0067b71f9908b128909d.png" style="width:25%">
	<img class="mySlides6" src="/NNNW/UnidentifiedNavigatingObject/130e45078899b15b63d30a4a.png" style="width:25%">
	<img class="mySlides6" src="/NNNW/UnidentifiedNavigatingObject/16fe13be5357d77b411eb0a6.png" style="width:25%">
	<img class="mySlides6" src="/NNNW/UnidentifiedNavigatingObject/30ccdb92810a3248933a0de8.png" style="width:25%">
	<img class="mySlides6" src="/NNNW/UnidentifiedNavigatingObject/3c04fe5bfa05abd0b4967aa9.png" style="width:25%">
	<img class="mySlides6" src="/NNNW/UnidentifiedNavigatingObject/4c65f79df0764cc5be29eca9.png" style="width:25%">
	<img class="mySlides6" src="/NNNW/UnidentifiedNavigatingObject/5f5eba2dc933bdd6cbf04015.png" style="width:25%">
	<img class="mySlides6" src="/NNNW/UnidentifiedNavigatingObject/640c91d11c1acc99dbfd.png" style="width:25%">
	<img class="mySlides6" src="/NNNW/UnidentifiedNavigatingObject/6b3127fc36b7118072017e39.png" style="width:25%">
	<img class="mySlides6" src="/NNNW/UnidentifiedNavigatingObject/9e9798b42f73f539ff5a916e.png" style="width:25%">

	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs6(-1)">&#10094;</button>
</div>
<script>
var slideIndex6 = 1;
showDivs6(slideIndex6);

function plusDivs6(n) {
  showDivs6(slideIndex6 += n);
}

function showDivs6(n) {
  var m;
  var c = document.getElementsByClassName("mySlides6");
  if (n > c.length) {slideIndex6 = 1}
  if (n < 1) {slideIndex6 = c.length}
  for (m = 0; m < c.length; m++) {
    c[m].style.display = "none";  
  }
  c[slideIndex6-1].style.display = "block";  
}
</script>
	
<!------------------------------------------------------------------------- wildBot -->
<div class="w3-panel">
	<div class="w3-panel">
		<p style="color:#fff; font-size:15px; font-family: SpaceGL">class wildBot</p>
	</div>
</div>
	
<div class="w3-content w3-display-container">
  	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs7(1)">&#10095;</button>
	
  	<img class="mySlides7" src="/NNNW/wildBot/1f65d6ea481d8b22610782c5.png" style="width:25%">
	<img class="mySlides7" src="/NNNW/wildBot/1f7a8054d7842267c9d8717b.png" style="width:25%">
	<img class="mySlides7" src="/NNNW/wildBot/2dcb64b14b154c9ed27dcb02.png" style="width:25%">
	<img class="mySlides7" src="/NNNW/wildBot/39af7dd5acca34215706dd9a.png" style="width:25%">
	<img class="mySlides7" src="/NNNW/wildBot/4ba4948c593dbb8546815ece.png" style="width:25%">
	<img class="mySlides7" src="/NNNW/wildBot/5ba6f085bdd99ea4df498242.png" style="width:25%">
	<img class="mySlides7" src="/NNNW/wildBot/78ffa1084d80cc042447169d.png" style="width:25%">
	<img class="mySlides7" src="/NNNW/wildBot/7d911a3acd51cfb4dc7057eb.png" style="width:25%">
	<img class="mySlides7" src="/NNNW/wildBot/7dc94f91049e2c1d65c2cb49.png" style="width:25%">
	<img class="mySlides7" src="/NNNW/wildBot/83d7674376244bc9d8b16a5d.png" style="width:25%">

	<button class="w3-button w3-black" style="width:100%" onclick="plusDivs7(-1)">&#10094;</button>
</div>
<script>
var slideIndex7 = 1;
showDivs7(slideIndex7);

function plusDivs7(n) {
  showDivs7(slideIndex7 += n);
}

function showDivs7(n) {
  var m;
  var c = document.getElementsByClassName("mySlides7");
  if (n > c.length) {slideIndex7 = 1}
  if (n < 1) {slideIndex7 = c.length}
  for (m = 0; m < c.length; m++) {
    c[m].style.display = "none";  
  }
  c[slideIndex7-1].style.display = "block";  
}
</script>
<!------------------------------------------------------------------------- NewNewNewWorld_Explorer ----------------------------------------------------->
<div class="w3-container w3-padding-32" id="retratos">
  <h3 class="w3-border-bottom w3-border-light-grey w3-padding-16 Museo-font"  style="color:#ffffff; font-size: 25px">NewNewNewWorld_Explorer</h3>
</div>

<div class="w3-panel" style="margin: auto; width:1000px">
	<p style="color:#ffffff; font-size:17px; font-family: Museo">The xenobjects’ on-screen and off-screen existence has required, up to date, a human mediation –specifically human sensing– that can prompt BigGAN’s generation of xenobjects as 2D images. Given that there were no AI models trained on these objects—because they didn’t previously exist—this task could have been very hardly automated through current AI techniques. So far, human vision that entails symbolic cognition and complex perceptual training is the best to identify imagined (imaged) novel objects that could be mapped and printed on- and off-screen.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">But in fact, the automation of NNNW’s exploration has already started, not only as my own visual training but also as the training of an AI co-pilot that helps me to refine the classification –to consider possible misclassifying and possible classes not yet identified. The NNNW_Explorer is the first Machine Learning model trained on the NNNW_Archive dataset, and shares with me the speculative-realist function of providing evidence of the BigGAN’s objective capacity for creative, post-human, object-oriented worldbuilding, beyond any fabulation I could narratively convince you into –i.e. the function of arguing in favor of the existence of the NNNW_Constructor.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">An “objective” fact, or “objective” knowledge, following Pablo Fernández Christlieb (2004), here means knowledge that has been subjected to the objection of other objects. If culture is a sort of inter-subjective knowledge, I’m looking for it’s un-severing from science as inter-objective knowledge. My counterfactual statement being “if the BigGAN wasn’t a NNNW_Constructor, it would not be able to generate xenobjects”, the NNNW_Explorer is here to make an objection about it. The wanted following assertion –to which, if this research is succesful, neither myself, neither the NNNW_Explorer, nor yourself nor many other objects will object– is of course that the xenobjects exist and that the NNNW can be printed.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">The way the NNNW_Explorer works is, it takes an image of a test set corresponding to a NNNW_Archive class or to an ImageNet class, and assess its resemblance to the classes of both datasets. In doing so, it evaluates both the differentiability of xenobjects (from ImageNet objects) and the differentiability between xenobjects (one class from one another). The difference between the evaluated xenobject and the ImageNet objects will be given by how much it’s 100% resemblance is shared by ImageNet and by NNNW_Archive classes. The difference between the evaluated xenobject and other xenobjects will be given by how much it’s 100% resemblance is shared by other NNNW_Archive classes.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Nevertheless, that’s just how the NNNW_Explorer would ideally work. For the moment, it has not yet be trained on ImageNet as it is a huge dataset that will demand more time and resources, so it’s only capable of evaluating the existence of different types of xenobjects.
     	</p>
</div>
<!------------------------------------------------------------------------- NNNW_Explorer VIDEO ---------------------------------------------------------------------->
<div class="w3-padding-16 w3-center" style="margin:auto; max-width:500">
	<iframe src="https://player.vimeo.com/video/707603911?h=10936d2249&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" width="1280" height="720" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="NNNW_Explorer test"></iframe>
<!--<div class="w3-panel" style="margin:auto; width:1564">-->
</div>
<!------------------------------------------------------------------------- Post-contemporary Malitzin --------------------------------------------------------------->
<div class="w3-container w3-padding-32" id="retratos">
  <h3 class="w3-border-bottom w3-border-light-grey w3-padding-16 Museo-font"  style="color:#ffffff; font-size: 25px">Post-contemporary Malitzin</h3>
</div>

<div class="w3-panel" style="margin: auto; width:1000px">
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Indeed I’m engaging with politics of designation and politics of objectification. I feel like playing the role of a post-contemporary Malitzin, or Maliche (or both), who mediated the end of the world for pre-columbian cultures and the rising of the New Spain as the personal translator (and lover) of Hernán Cortés, head of the conquest of Tenochtitlan (the capital of the Aztec empire) and other Mesoamerican cities and cultures.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">“A world in fact is the projection of meaningful patterns onto the surrounding space of lived experience”, says Berardi (2015), and I’m in a way creating a world by projecting meaningful patterns into your surroundings. Yes, my practice is about projecting the bias in my own neural net to some extent. But it is also to do as much as I can to see beyond the categories in which I’ve been trained. In fact, it is to become able to see other categories. It is to say “that’s a stemBot” where you would say “that’s a bug”. It is to say “that’s a xenobject” where you would say “that doesn’t look like anything to me”. It is not to be a Dutch cartographer at the middle of the past millennium, and it is in fact not to be a TERF at the beginning of the current.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">It’s me and the BigGAN who are projecting patterns onto your surroundings. Just as I don’t want anyone to “lose their ability to feel like they are part of a common evolving reality” (Berardi, 2’015), I want every agent in my shared reality to have the feeling that they are part of a common evolving reality. This is an excersise on doing so with an agent developed to reproduce the meaningful patterns of others.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Computational culture seem to have the potential to supersede every non-computational culture. How can we make the computaional worldbuilding a symbiosis instead of a conquest? Perhaps suscribing to a Malitzin() function and to the practice of “opening to the incomprehensible other […] and reinventing language”, and culture, in order to transform the probabilities of catastrophe into the probabilities of anastrophe.
     	</p>
</div>

<!------------------------------------------------------------------------- References --------------------------------------------------------------->
<div class="w3-container w3-padding-32" id="retratos">
  <h3 class="w3-border-bottom w3-border-light-grey w3-padding-16 Museo-font"  style="color:#ffffff; font-size: 25px">References</h3>
</div>

<div class="w3-panel" style="margin: auto; width:1000px">
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Malinche and the End of the World, Franco ‘Bifo’ Berardi, 2015
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Avanessian, Armen and Malik, Suhail, eds. 2016. The Time Complex: Post-Contemporary. Miami, Florida: [NAME].
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Excavating AI: The Politics of Training Sets for Machine Learning, Kate Crawford and Trevor Paglen, September 19, 2019, https://excavating.ai
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">The Data That Transformed AI Research—and Possibly the World, Dave Gershgorn, Quartz, July 26, 2017
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Andrej Karpathy, Software 2.0, 2017
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Program Earth, Jennifer Gabrys, 2016
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Sensing the Virtual, Building the Insensible, Brian Massumi, 1988
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Andrew Brock + Jeff Donahue + Karen Simonyan, LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS, 2019
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">BigGanEx: A Dive into the Latent Space of BigGan, Zaid Alyafeai, 2018
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Inventing America, José Rabasa, 1993
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Antonio Barrera-Osorio, Nature and Experience in the New World: Spain and England in the Making of the New Science, 2007 (in Beyond the Black Legend: Spain and the Scientific Revolution, Víctor Navarro Brotóns (coord.), William Eamon (coord.), Universitat de València, 2007)
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">How to Rewrite the Laws of Physics in the Language of Impossibility (interview to Chiara Marletto), Amanda Gefter, Quanta Magazine, 2021.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Encyclopedia of Social Science Research Methods, edited by Michael Lewis-Beck (University of Iowa), Alan Bryman (Loughborough University), and Tim Futing Liao.  Sage Publications, 2004.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Cyberpositive, Nick Land and Sadie Plant, 1994.
     	</p>
	<p style="color:#ffffff; font-size:17px; font-family: Museo">Pablo Fernández Christlieb, La Sociedad Mental, Anthropos, 2004.
     	</p>
<!------------------------------------------------------------------------- NNNW_Explorer sketch 
<div class="w3-padding-16 w3-center">
	<script src="sketches/NNNW_Explorer/sketch.js"></script>
</div>-->
	
<!----------------------------------- fossil_to_xeno
<div class="w3-padding-16 w3-center">
	<iframe title="vimeo-player" src="https://player.vimeo.com/video/396808424" width="640" height="500" frameborder="0" allowfullscreen></iframe>
	<div class="w3-panel" style="margin: auto; width:500px">
</div>-->

<!--
<div class="w3-panel" style="margin: auto; width:1000px">
		<p style="color:#ffffff; font-size:17px; font-family: Museo">This is...</p>
</div>
-->

<div class="w3-right-align w3-container Museo-font">
	<p style="color:#fff; font-size:25px"><a href="/project_XGC.html">Next project ></a></p>
</div>

   
</body>
</html>
